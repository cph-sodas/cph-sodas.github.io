{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the SODAS Documentation","text":"<p>Find relevant documentation and information about SODAS here.</p> <p>The docs live on GitHub, please feel free to contribute or create an issues there if you have any none urgent problems or suggestions.</p>"},{"location":"cheatsheets/","title":"Cheatsheets","text":""},{"location":"server/","title":"Server","text":"<p>Welcome to the SODAS server documentation.</p> <p>Before you start using the server, please make sure that you read all the three pages in this part of the documentation:</p> <ol> <li>How to access the server</li> <li>How to setup a project and your developer environment</li> <li>How to use the computational resources through Slurm</li> </ol> <p>Please also consider consulting the official UCPH documentation.</p> <p>We have also collected some general tips &amp; tricks for working with the server and Linux, and some guides for specific tasks.</p>"},{"location":"server/#whats-new","title":"What's new?","text":"<p>Compared to the old server, there are three main differences:</p> <p>One: the new server uses Slurm for compute resource management. This means that the server you log in to is just a middle layer, and that to access the compute resources of the old server (i.e. the GPUs, memory, CPU) one must use the Slurm commands (see under usage).</p> <p>Two: To better structure projects and data, all projects should be stored in the <code>/projects/</code>. These are <code>compute projects</code> and are created through the self service portal (see setup). When you access the compute resources through Slurm, your code and data must be in a projects directory, since that server does not have access to your other network drives.</p> <p>Three: We strongly recommend that you use <code>uv</code> to manage your Python projects and virtual environments, one reason being the difficulties around the licensing of conda default channels, the other that <code>uv</code> helps you enforce better reproducibility, and is most use cases also faster.</p> <p>This is also new for us, so please reach out with any questions or suggestions for improvement, but please be patient.</p>"},{"location":"server/access/","title":"Access","text":"<p>In order to access the server, you need to contact the datalab with your basic information and SODAS affiliation, and they will help setup up an account for you. The process currently takes a bit of time, so please be patient while we look into ways of optimizing this.</p>"},{"location":"server/access/#connecting-to-the-server","title":"Connecting to the server","text":"<p>First of all, you need to be connected to UCPH's network through the VPN. See the guides on the intranet. Our friends at DIKU also have a guide for using a VPN with UCPH's network for linux and mac users.</p> <p>Warning</p> <p>It is (currently) not enough to be on the cabled network at UCPH, you need to be connected to the VPN.</p> <p>You connect to the server using SSH. See tips on SSH here. An SSH connection to the server can be established either through your terminal of choice or e.g. VSCode.</p> <p>Note</p> <p>Windows users can use the build in command prompt to run the following commands, or download Windows Terminal for a better experience.</p>"},{"location":"server/access/#terminal","title":"Terminal","text":""},{"location":"server/access/#ssh","title":"SSH","text":"<pre><code>ssh &lt;username&gt;@sodashead01fl.unicph.domain\n</code></pre> <p>To connect locally to the server with the user abc123, do:</p> <pre><code>ssh abc123@sodashead01fl.unicph.domain\n</code></pre> <p>Note</p> <p>You can specify a specific address and port to connect to, eg:</p> <pre><code>ssh -L 8000:localhost:8000 abc123@sodashead01fl.unicph.domain\n</code></pre>"},{"location":"server/access/#transferring-files","title":"Transferring files","text":""},{"location":"server/access/#transfer-from-local-to-server","title":"Transfer from local to server","text":"<pre><code>scp /path/to/file &lt;username&gt;@sodashead01fl.unicph.domain:/path/to/destination\n</code></pre> <p>To move a text file in documents to your H-drive which is mounted on the server by default, do:</p> <pre><code>scp /documents/test.txt abc123@sodashead01fl.unicph.doman:/ucph/hdir\n</code></pre>"},{"location":"server/access/#transfer-file-from-server-to-local","title":"Transfer file from server to local","text":"<pre><code>scp &lt;username&gt;@sodashead01fl.unicph.domain:/path/to/file /path/to/destination\n</code></pre> <p>To move a text file from the H-drive on the server to your local documents folder, do:</p> <pre><code>scp abc123@sodashead01fl.unicph.doman:/ucph/hdir/test.txt /documents\n</code></pre>"},{"location":"server/access/#vscode","title":"VSCode","text":"<p>You can access the server through VSCode by installing the Remote - SSH extension. Follow the instructions in the documentation to connect to the server.</p> <p>Then, when connected, install the python and juyter extensions on the remote.</p> <p>To make the compute resources from slurm available in vscode, see under usage.</p>"},{"location":"server/setup/","title":"Setup","text":"<p>The setup guide walks you through the process of setting up your developer environment on the SODAS server.</p>"},{"location":"server/setup/#projects","title":"Projects","text":"<p>All compute projects are stored in the <code>/projects/</code>folder.</p> <pre><code>abc123@sodashead01fl /projects/main_compute-AUDIT $ tree -L 1\n.\n\u251c\u2500\u2500 apps\n\u251c\u2500\u2500 data\n\u251c\u2500\u2500 people\n\u2514\u2500\u2500 scratch\n</code></pre> <p>Warning</p> <p>Since the compute server (which is accessed via Slurm) does not have access to other network drives (i.e. h-drive and s-drives), you must store your project data and code in a compute project directory.</p> <p>You can make a request for a new project at the UCPH service portal. Select <code>FS-sodas</code> under FS system.</p> <p>After the project has been created, you probably also need to give read/write access to yourself in identity management.</p>"},{"location":"server/setup/#configuration","title":"Configuration","text":"<p>Tip</p> <p>Remeber to source your <code>.bashrc</code> after modifying it. You can do this by <pre><code>source ~/.bashrc\n</code></pre></p>"},{"location":"server/setup/#shared-cache","title":"Shared cache","text":"<p>TBD</p>"},{"location":"server/setup/#install-custom-software","title":"Install custom software","text":""},{"location":"server/setup/#uv","title":"uv","text":"<p>Install <code>uv</code>:</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <p>There are two different strategies for managing your virtual environments.</p> <p>You can either do it by creating named environments in the <code>~/.virtualenvs/</code> folder, or by creating them locally in a <code>.venv</code> folder in your project.</p> <p>TBD: Test what is fastest</p>"},{"location":"server/setup/#python-projects","title":"Python projects","text":"<p>To make uv work on the network drives properly, you have to change the following setting first.</p> <pre><code>echo \"export UV_LINK_MODE=symlink\" &gt;&gt; ~/.bashrc\n</code></pre> <p>To get the full benefit of <code>uv</code>, you should initialize your python projects in the desired folder. This could be <code>/projects/my_project/people/abc123/python/</code> or <code>/projects/my_project/apps/python/</code>.</p> <p>When you have navigated to the desired folder, you can run</p> <pre><code>uv init\n</code></pre> <p>This will create some boiler plate, which will allow you to take advantage of uv's dependency management.</p> <p>Tip</p> <p>Specify the python version with</p> <pre><code>uv init --python 3.9\n</code></pre> <p>Then, to add a project dependency, you can run:</p> <pre><code>uv add matplotlib\n</code></pre> <p>This will add the dependency to the <code>uv.lock</code> and <code>pyproject.toml</code> files, and install it into the <code>venv</code>.</p> <p>Tip</p> <p>uv stores venvs in .venv folder in the project directory, and initializes them automatically with the above steps. You can also create a venv manually by running <code>uv venv</code></p> <p>If you later found it it isn't needed for your project, you can remove it with:</p> <pre><code>uv remove matplotlib\n</code></pre> <p>To run your scripts, you can use the <code>uv run</code> command:</p> <pre><code>uv run my_script.py\n</code></pre>"},{"location":"server/setup/#using-your-environments","title":"Using your environments","text":"<p>First you must activate your environment.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Tip</p> <p>Add a function to your to easily activate virtual environments either named or local from anywhere on the server:</p> <pre><code>echo 'function activate() { if [ -n \"$1\" ]; then source ~/.virtualenvs/\"$1\"/bin/activate; else source ./.venv/bin/activate; fi; }' &gt;&gt; ~/.bashrc\n</code></pre> <p>This function will activate the virtual environment in the current directory, or from the name of the virtual environment.</p> <p>You can then activate the environment by running <code>activate</code> or <code>activate my-project</code>.</p>"},{"location":"server/setup/#named-environments","title":"Named environments","text":"<p>If you prefer named virtual environments, you can store them in <code>~/.virtualenvs/</code>.</p> <pre><code>mkdir ~/.virtualenvs\n</code></pre> <p>Here you can create new named virtual environments</p> <pre><code>cd ~/.virtualenvs\nuv venv my-project\n</code></pre>"},{"location":"server/setup/#jupyterlab","title":"JupyterLab","text":"<p>Warning</p> <p>The following steps do not fully work, since <code>uv</code> havn't added --include-deps flag yet</p> <p>To install jupyterlab system-wide, we can run:</p> <pre><code>uv tool install jupyterlab\n</code></pre> <pre><code>echo \"alias jlab=\\\"jupyter-lab --port=8880 --ip=10.84.10.216 --no-browser\\\"\" &gt;&gt; ~/.bashrc\necho \"alias jadd=\\\"python -m ipykernel install --user --display-name \\${PWD} --name \\${PWD##*/}\\\"\" &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"server/setup/#zsh","title":"zsh","text":"<p>In this step of the guide, we will take you throw setting up zsh as your default shell, and installing starship as your prompt.</p>"},{"location":"server/setup/#building-from-source","title":"Building from source","text":"<p>Make directories for local installations and downloads</p> <pre><code>mkdir local\nmkdir downloads\n</code></pre> <p>Download the latest version of zsh</p> <pre><code>cd downloads\nwget -O zsh.tar.xz https://sourceforge.net/projects/zsh/files/latest/download\n</code></pre> <p>Unpack the tarball</p> <pre><code>mkdir zsh &amp;&amp; unxz zsh.tar.xz &amp;&amp; tar -xvf zsh.tar -C zsh --strip-components 1\n</code></pre> <p>Build zsh from source</p> <pre><code>cd zsh\n./configure --prefix=$HOME/local\nmake\nmake install\n</code></pre> <p>Remove the downloaded files</p> <pre><code>rm -rf ~/downloads/zsh*\n</code></pre> <p>Find configuration examples online.</p>"},{"location":"server/setup/#starship","title":"Starship","text":"<p>To get a better prompt, you can install starship:</p> <pre><code>curl -sS https://starship.rs/install.sh | sh -s -- --bin-dir ~/bin/\n</code></pre> <p>And add the following to your <code>~/.zshrc</code>:</p> .zshrc<pre><code>eval \"$(starship init zsh)\"\n</code></pre> Example <p>Here is an example of a <code>starship.toml</code> configuration file, it can be saved in <code>~/.config/starship.toml</code></p> starship.toml<pre><code>format = \"\"\"\n[\ue0b6](#9A348E)\\\n$username\\\n$hostname\\\n[\ue0b0](bg:#DA627D fg:#9A348E)\\\n$directory\\\n[\ue0b0](fg:#DA627D bg:#FCA17D)\\\n$git_branch\\\n$git_status\\\n[\ue0b0](fg:#FCA17D bg:#86BBD8)\\\n$nodejs\\\n$python\\\n[\ue0b0](fg:#86BBD8 bg:#06969A)\\\n$docker_context\\\n[\ue0b0](fg:#06969A bg:blue)\\\n$custom\\\n[\ue0b0](fg:blue) \\\n\"\"\"\n\nright_format=\"\"\"\n$status $cmd_duration $time\n\"\"\"\n\n# Disable the blank line at the start of the prompt\nadd_newline = false\n\n# You can also replace your username with a neat symbol like \uf120  or disable this\n# and use the os module below\n[username]\nshow_always = true\nstyle_user = \"bg:#9A348E\"\nstyle_root = \"bg:#9A348E\"\nformat = \"[$user]($style fg:black)\"\ndisabled = false\n\n[hostname]\nssh_symbol=\"@\"\nstyle=\"bg:#9A348E\"\nformat=\"[$ssh_symbol$hostname]($style fg:black)\"\n\n[directory]\nstyle = \"bg:#DA627D fg:black\"\nformat = \"[ $path ]($style)\"\ntruncation_length = 3\ntruncation_symbol = \"\u2026/\"\n\n# Here is how you can shorten some long paths by text replacement\n# similar to mapped_locations in Oh My Posh:\n[directory.substitutions]\n\"Documents\" = \"\udb80\ude19 \"\n\"Downloads\" = \"\uf019 \"\n\"Music\" = \"\uf001 \"\n\"Pictures\" = \"\uf03e \"\n# Keep in mind that the order matters. For example:\n# \"Important Documents\" = \" \udb80\ude19\uf12a \"\n# will not be replaced, because \"Documents\" was already substituted before.\n# So either put \"Important Documents\" before \"Documents\" or use the substituted version:\n# \"Important \udb80\ude19 \" = \" \udb80\ude19\uf12a \"\n\n[docker_context]\nsymbol = \"\uf308 \"\nstyle = \"bg:#06969A\"\nformat = '[ $symbol $context ]($style)'\n\n[git_branch]\nsymbol = \"\uf418\"\nstyle = \"bg:#FCA17D black\"\nformat = '[ $symbol $branch ]($style)'\n\n[git_status]\nstyle = \"bg:#FCA17D black\"\nformat = '[$all_status$ahead_behind ]($style)'\n\n[nodejs]\nsymbol = \"\ue718\"\nstyle = \"bg:#86BBD8\"\nformat = '[ $symbol ($version) ]($style)'\n\n[python]\nstyle = \"bg:#86BBD8 black\"\nsymbol = \" \ue73c \"\nformat = '[${symbol}($virtualenv) ]($style)'\n\n[status]\nformat = '[$symbol$common_meaning$signal_name$maybe_int]($style) '\nmap_symbol = true\ndisabled = false\n\n[cmd_duration]\nmin_time = 500\nformat = '[$duration](bold yellow)'\n\n[time]\ndisabled = false\ntime_format = \"%R\" # Hour:Minute Format\nstyle = \"\"\nformat = '[\uf017  $time]($style)'\n\n[custom.slurm]\ncommand = \"\"\"\nif [ ! -z \"${SLURM_JOB_ID}\" ]; then\n    echo \"\udb86\udd52 ${SLURM_JOB_ID}\"\nfi\n\"\"\"\nwhen = \"[ ! -z \\\"${SLURM_JOB_ID}\\\" ]\"\ndescription = \"Display current Slurm job ID\"\nstyle = \"bg:blue black\"\nformat = \"[ $output ]($style)\"\n</code></pre>"},{"location":"server/setup/#environment-variables","title":"Environment Variables","text":"<p>TBD</p>"},{"location":"server/setup/#github","title":"Github","text":""},{"location":"server/setup/#generate-ssh-key","title":"Generate SSH key","text":"<p>Follow the guide at GitHub.</p>"},{"location":"server/setup/#ssh-config","title":"SSH Config","text":"<p>Create a config file at <code>~/.ssh/config</code> and add the following lines:</p> <pre><code>Host github.com\n    HostName ssh.github.com\n    PreferredAuthentications publickey\n    IdentityFile ~/.ssh/id_ed25519\n    Port 443\n</code></pre>"},{"location":"server/tips/","title":"Tips","text":"<p>In general, reading the official documentation of all the tools you use in data science and on the computer is underrated. In my experience (Jonas) it always pays off in the long run to spend some time reading the documentation on the tools that I use.</p> <p>Here, we list different tips and tricks for the most common tools encountered when using the SODAS server and on establishing a nice workflow on the server in general.</p>"},{"location":"server/tips/#bash","title":"bash","text":"<p>The server runs on a Linux distribution. In the following section we will provide some simple commands which may help you work your way around the server.</p>"},{"location":"server/tips/#navigation","title":"Navigation","text":"<pre><code>pwd                 # Show current directory (Print Working Directory)\nls                  # List files and folders in current directory\nls -l               # List files with details (permissions, size, date)\nls -a               # List files including hidden files (i.e. starting with `.`)\ncd DirectoryName    # Change to specified directory\ncd ..               # Go up one directory level\ncd ~                # Go to your home directory\n</code></pre>"},{"location":"server/tips/#working-with-files-and-folders","title":"Working with Files and Folders","text":"<pre><code>mkdir FolderName        # Create a new folder\ntouch filename.txt      # Create a new file\ncp file1 file2          # Copy file1 to file2\nmv file1 file2          # Move or rename file1 to file2\nrm filename             # Delete a file (be careful, no recycling bin!)\nrm -r foldername        # Delete a folder and its contents\ngrep -r \"search term\" . # Search for a term in all files in current directory\n</code></pre>"},{"location":"server/tips/#viewing-file-contents","title":"Viewing File Contents","text":"<pre><code>cat filename       # Display entire file content\nless filename      # View file content page by page (use q to quit)\nhead filename      # Show first 10 lines of file\ntail filename      # Show last 10 lines of file\n</code></pre>"},{"location":"server/tips/#common-tasks","title":"Common Tasks","text":"<pre><code>clear              # Clear the terminal screen\nhistory            # Show command history\nman command        # Show manual for a command\n</code></pre>"},{"location":"server/tips/#extra","title":"Extra","text":"<pre><code>uuidgen           # Generate a random UUID\ncal               # Show a simple calendar\nbtop              # Interactive process viewer\n</code></pre> <p>Tip</p> <ul> <li>Use Tab key to auto-complete file/folder names</li> <li>Use Up/Down arrow keys to navigate through previous commands</li> </ul> <p>Note</p> <ol> <li>Linux commands are case-sensitive</li> <li>Spaces in file/folder names need quotation marks or escape characters</li> <li>Be extra careful with <code>rm</code> commands - deleted files cannot be recovered easily</li> </ol>"},{"location":"server/tips/#ssh","title":"SSH","text":"<ul> <li>Lecture note from MIT missing semester course on remote machines (and SSH)<ul> <li>Nice explanation of ssh, port forwarding and ssh configuration<ul> <li>Highly recommended to read the other parts of the lecture notes as well!</li> </ul> </li> </ul> </li> </ul>"},{"location":"server/tips/#ssh-config-file","title":"ssh config file","text":"<p>On your local machine which you connect from, you can create a config to save the ssh connection specification</p> <ul> <li>create your config file <code>~/.ssh/config</code></li> <li>here you define different hosts to avoid writing the long server name each   time</li> </ul> <pre><code>Host sodashead\n  HostName sodashead01fl.unicph.domain\n  User abc123\n</code></pre> <ul> <li>then you can type</li> </ul> <pre><code>ssh sodashead\n</code></pre> <p>instead of</p> <pre><code>ssh abc123@sodashead01fl.unicph.domain\n</code></pre> <p>each time</p>"},{"location":"server/tips/#connecting-to-server-without-typing-password","title":"connecting to server without typing password","text":"<ul> <li>download sshpass using your package   manager of choice (e.g. <code>brew</code> on mac)</li> <li>use a password manager e.g. pass to store   your password on the command line</li> <li>now you can connect to the server by typing</li> </ul> <pre><code>SSHPASS=$(pass kup) sshpass -e ssh sodashead\n</code></pre> <ul> <li> <p>bonus:</p> <ul> <li> <p>define a script somewhere on your computer and make sure it is in your path</p> <ul> <li> <p>For instance, I have the script named <code>sodashead</code> (shown below) in my path</p> <pre><code>#!/usr/bin/env bash\nSSHPASS=$(pass kup) sshpass -e ssh sodashead\n</code></pre> </li> </ul> </li> </ul> <ul> <li>now you can simply type <code>sodashead</code> (or whatever your script is named) to   connect to the server</li> </ul> </li> </ul>"},{"location":"server/tips/#tmux","title":"tmux","text":"<ul> <li>Lecture note from MIT missing semester   course   on terminal multiplexers (of which tmux is an example)</li> <li>Getting started   tmux documentation</li> <li>The tao of tmux</li> </ul>"},{"location":"server/tips/#finding-help-for-different-commands","title":"finding help for different commands","text":""},{"location":"server/tips/#help-flag","title":"help flag","text":"<p>To find help for commands on a Linux server, there are several options available. A quick way to get an overview of a command is to use the <code>-h</code> or <code>--help</code> flags, which provide brief explanations. E.g. for the <code>ls</code> command:</p> <pre><code>[abc123@sodashead01fl ~]$ ls --help\nUsage: ls [OPTION]... [FILE]...\nList information about the FILEs (the current directory by default).\nSort entries alphabetically if none of -cftuvSUX nor --sort is specified.\n\nMandatory arguments to long options are mandatory for short options too.\n  -a, --all                  do not ignore entries starting with .\n  -A, --almost-all           do not list implied . and ..\n      --author               with -l, print the author of each file\n  -b, --escape               print C-style escapes for nongraphic characters\n      --block-size=SIZE      with -l, scale sizes by SIZE when printing them;\n                               e.g., '--block-size=M'; see SIZE format below\n  -B, --ignore-backups       do not list implied entries ending with ~\n  -c                         with -lt: sort by, and show, ctime (time of last\n                               modification of file status information);\n                               with -l: show ctime and sort by name;\n                               otherwise: sort by ctime, newest first\n  -C                         list entries by columns\n# ... Rest omitted for brievity\n</code></pre>"},{"location":"server/tips/#man-pages","title":"man pages","text":"<p>For more detailed information, you can use the <code>man</code> command (short for \"manual\"), which displays a comprehensive manual page, including command behaviors and flags. Even third-party commands often have manpages if developers include them. E.g. typing <code>man tmux</code> will open the man page for tmux in your manpager of choice (less pr default; you go up and down by pressing <code>j</code> and <code>k</code>):</p> <pre><code>TMUX(1)                   BSD General Commands Manual                  TMUX(1)\n\nNAME\n     tmux \u2014 terminal multiplexer\n\nSYNOPSIS\n     tmux [-2CluvV] [-c shell-command] [-f file] [-L socket-name]\n          [-S socket-path] [command [flags]]\n\nDESCRIPTION\n     tmux is a terminal multiplexer: it enables a number of terminals to be\n     created, accessed, and controlled from a single screen.  tmux may be\n     detached from a screen and continue running in the background, then later\n     reattached.\n\n# ... Rest omitted for brievity\n</code></pre> <p>Try for instance navigating to the DEFAULT KEY BINDINGS section of the tmux man page.</p>"},{"location":"server/tips/#tldr","title":"tldr","text":"<p>If manpages are too detailed, TLDR pages offer simplified examples and common use cases, making them a great complementary resource. See the tldr docs.</p>"},{"location":"server/tips/#makefiles","title":"Makefiles","text":"<p>TBD</p>"},{"location":"server/tips/#git","title":"git","text":"<p>TBD</p>"},{"location":"server/tips/#management-utilities","title":"Management utilities","text":"<p>Display unicph ID information</p> <pre><code>kuid &lt;username&gt;\n</code></pre> <p>Check server access for specific user</p> <pre><code>id &lt;username&gt; | tr \",\" \"\\n\" | grep srv-sodas\n</code></pre> <p>Check users logged on the server</p> <pre><code>users\nw\n</code></pre> <p>Custom function to lookup multiple KUIDs (can be added to <code>.bashrc</code>):</p> <pre><code>function kuids() {\n  while read -r username; do\n    if [[ $username =~ ^[a-zA-Z]{3}[0-9]{3}$ ]]; then\n      kuid \"$username\"\n      echo \"============================\"\n    fi\n  done\n}\n</code></pre> <p>Usage:</p> <pre><code>ls /home/ | kuids\nusers | tr \" \" \"\\n\" | kuids\n</code></pre>"},{"location":"server/tips/#misc","title":"misc","text":"<ul> <li>a tip</li> </ul>"},{"location":"server/usage/","title":"Usage","text":"<p>All usage of computer resources is manged through the Slurm<sup>1</sup> Workload Manager.</p> <p>In addition, the server is equipped with a number of modules that can be loaded through the <code>module</code> command.</p>"},{"location":"server/usage/#modules","title":"Modules","text":"<p>Modules are pre-compiled software that you can load into your shell environment.</p> <p>To see the available modules, you can run the following command:</p> <pre><code>module avail\n</code></pre> <p>And to load a module:</p> <pre><code>module load &lt;module-name&gt;\n</code></pre> <p>And unload again:</p> <pre><code>module unload &lt;module-name&gt;\n</code></pre>"},{"location":"server/usage/#slurm","title":"Slurm","text":"<p>Slurm is a job scheduler and resource manager for the compute resources available.</p>"},{"location":"server/usage/#status","title":"Status","text":"<p>To see the attached resources, you can run the following command:</p> <pre><code>sinfo -N -l\n</code></pre> <p>To see the jobs that are currently running, you can run the following command:</p> <pre><code>squeue\n</code></pre> <p>for a specific user:</p> <pre><code>squeue -u &lt;username&gt;\n</code></pre>"},{"location":"server/usage/#submitting-jobs","title":"Submitting jobs","text":""},{"location":"server/usage/#batch-jobs","title":"Batch jobs","text":"<p>A typical SLURM script consists of three main sections:</p> <ol> <li>SLURM directives (#SBATCH)</li> <li>Environment setup</li> <li>Execution commands</li> </ol> <p>Here's a detailed example:</p> script.sh<pre><code>#!/bin/bash\n\n#----------------------------------------\n# SLURM Directives\n#----------------------------------------\n#SBATCH --chdir=/projects/main_compute-AUDIT/    # Working directory\n#SBATCH --job-name alphafoldtestjobname          # Job name\n#SBATCH --mem=50G                                # Memory requirement\n#SBATCH --ntasks=1                               # Number of tasks\n#SBATCH --cpus-per-task=1                        # CPU cores per task\n#SBATCH --nodes=1                                # Number of nodes\n#SBATCH --mail-type=begin                        # Email at job start\n#SBATCH --mail-type=end                          # Email at job end\n#SBATCH --mail-user=abc123@ku.dk                 # Email address\n#SBATCH --gres=gpu:1                             # GPU requirement\n#SBATCH --time=10:00:00                          # Maximum runtime of 10 hours\n\n#----------------------------------------\n# Environment Setup\n#----------------------------------------\n# Load required modules\nmodule load miniconda/4.10.4\nconda activate alphafold\n\n#----------------------------------------\n# Job Execution\n#----------------------------------------\n# Change to working directory\ncd /projects/main_compute-AUDIT/data/alphafold\n\n# Run the main script\nbash run_alphafold.sh \\\n    -d /projects/testproject1/data/genetic_databases/ \\\n    -o /projects/testproject1/people/btj820/ \\\n    -m model_1 \\\n    -f example/query.fasta \\\n    -t 2020-05-14\n</code></pre> <p>Run the script with:</p> <pre><code>sbatch script.sh\n</code></pre> <p>Once the job is submitted you will receive a job-id, which you can use to check the status of the job with:</p> <pre><code># Detailed job information\nscontrol show job &lt;job-id&gt;\n</code></pre> <p>Also, the output of the job will be saved in a file with the name <code>slurm-&lt;job-id&gt;.out</code> in the working directory specified.</p> <pre><code>tail -f slurm-&lt;job-id&gt;.out\n</code></pre> <p>Tip</p> <p>You can specify an output directory for your slurm outputs in your slurm script by adding:</p> <pre><code>#SBATCH --output=./slurm/slurm-%j.out                           # Output file path (%j is the job ID)\n</code></pre> <p>Note</p> <p>Make sure that the directory exists before running <code>sbatch</code> Ie: <code>mkdir slurm</code></p> <p>And then see follow the output of the last running job by running:</p> <pre><code>tail -F \"slurm/$(ls -t ./slurm | head -n 1)\"\n</code></pre> <p>To make this easier, you could add a function to your <code>.bashrc</code>:</p> <pre><code>echo '\nsfollow() {\n    local latest_file=$(ls -t ./slurm/ | head -n 1)\n    tail -n +1 -F \"./slurm/$latest_file\"\n}\n' &gt;&gt; ~/.bashrc\n</code></pre> <p>Then just type <code>sfollow</code> to see the output of a slurm job and follow it in real time.</p> <p>Get the node information:</p> <pre><code>scontrol show node\n</code></pre> <p>To stop a running job:</p> <pre><code>scancel &lt;job-id&gt;\n</code></pre>"},{"location":"server/usage/#interactive-jobs","title":"Interactive jobs","text":"<p>To start a simple interactive shell with 2 CPU cores, 5GB ram, 1 v100 GPU you can run the following command:</p> <p>Tip</p> <p>If copy pasting doesn't work for the multi line code snippets, try switching between selecting the text and using the copy button in the top right corner</p> <pre><code>srun -w sodasgpun01fl --partition=gpuqueue \\ #(1)!\n    --ntasks-per-node=2 \\ #(2)!\n    --mem=50GB \\ #(3)!\n    --gres=gpu:v100:1 \\ #(4)!\n    --time=240 \\ #(5)!\n    --pty /bin/bash -i #(6)!\n</code></pre> <ol> <li>Standard node and partition configuration</li> <li>Number of CPU cores</li> <li>Amount of memory (RAM)</li> <li>Number of GPUs</li> <li>Maximum time to run the task in minutes</li> <li>Run task in pseudo terminal.Change to <code>~/bin/zsh</code> if you installed zsh and wish to use that instead.</li> </ol> <p>This will start a new shell session with the allocated resources. This means that exiting the shell (e.g. when logging out of the server) will release the resources. To prevent this, you can start a persistent session with tmux.</p> <p>Check that you have access to the GPU by running</p> <p>Tip</p> <p>To run a new interactive shell session in an already running slurm job:</p> <pre><code>srun --jobid=&lt;slurm-id&gt; --pty /bin/bash -i\n</code></pre> <p>To request an extension of the time limit for a running job:</p> <pre><code>scontrol update JobId=&lt;job-id&gt; TimeLimit=&lt;new-time&gt;\n</code></pre> <pre><code>nvidia-smi\n</code></pre> <p>You will need to reload modules and/or activate environments in the new shell.</p> <pre><code>source .venv/bin/activate\n</code></pre>"},{"location":"server/usage/#jupyter-notebook","title":"Jupyter Notebook","text":"<p>To start a Jupyter Notebook, you need to first allocate resources on the server:</p> <pre><code>srun -w sodasgpun01fl --partition=gpuqueue \\\n  --ntasks-per-node=2 \\\n  --mem=5GB \\\n  --pty /bin/bash -i\n</code></pre> <p>Then, within the newly created interactive slurm session, and a folder containing a python uv project, run:</p> <pre><code>uv add jupyter\n</code></pre> <p>Activate the virtual environment:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Now, you can start the notebook server:</p> <pre><code>jupyter notebook --port=8880 --ip=10.84.10.216 --no-browser\n</code></pre> <p>Then copy the generated link and paste it in your local computer's browsers.</p> <p>I.e: <code>http://10.84.10.216:8800/?token=abcd1234...</code></p> <p>Info</p> <p>To above code works when you have entered an interactive slurm session. Don't change the port or the url, since they are required for access to the server.</p> <p>To start a jupyter notebook on the <code>head</code> node instead, you have to specify a port when you access the server via ssh, and then also refer to that port in the <code>jupyter notebook</code> command.</p> <pre><code>ssh -L 8000:localhost:8000 abc123@sodashead01fl.unicph.domain\n...\njupyter notebook --port=8000 --no-browser\n</code></pre>"},{"location":"server/usage/#vscode","title":"VSCode","text":"<p>In order to make the resources from slurm available to VSCode, follow the steps above and start a jupyter session.</p> <p>Then, in VSCode, when you open a Notebook Ctrl+Shift+P and search for <code>Notebook: Select Notebook Kernel</code>. If a kernel is already suggested, click <code>Select another kernel...</code> then <code>Existing Jupyter Server...</code> and copy the link with the token from above into the field.</p>"},{"location":"server/usage/#jupyter-kernels-and-virtual-environments","title":"Jupyter Kernels and Virtual Environments","text":"<p>TBD: When do you need to do this?</p> <p>To register a virtual environment with Jupyter, you can run the following command, from within your environment (that is, after activating it and making sure that <code>ipykernel</code> (<code>uv pip install ipykernel</code>) is installed).</p> <pre><code>python -m ipykernel install --user\n</code></pre>"},{"location":"server/usage/#persistent-sessions","title":"Persistent sessions","text":"<p>Use tmux to create and manage persistent sessions on the server.</p> <p>Start a new tmux session</p> <pre><code>tmux new -s &lt;session-name&gt;\n</code></pre> <p>List tmux sessions</p> <pre><code>tmux ls\n</code></pre> <p>Attach tmux session</p> <pre><code>tmux a -t &lt;session name&gt;\n</code></pre> <p>Detach (when you are inside) the session from tmux, leaving everything running in the background</p> <p>Ctrl+B D</p>"},{"location":"server/usage/#docker","title":"Docker","text":"<p>The server is equipped with a subset of docker, called udocker. It requires the anaconda3 module to be loaded first.</p> <pre><code>module load anaconda3/2020.11\nmodule load udocker\n</code></pre>"},{"location":"server/usage/#resources","title":"Resources","text":"<p>The UCPH guide to HPC systems</p> <p>Five part  video series  introducing Slurm</p> <p>The official slurm cheatsheet</p> <p>TMUX cheatsheet</p> <ol> <li> <p>Simple Linux Utility for Resource Management.\u00a0\u21a9</p> </li> </ol>"},{"location":"server/guides/","title":"Guides","text":"<p>A collection of guides for specific tasks.</p> <p>Please submit a guide through the github repository if you have a guide that you think would be useful for others.</p>"},{"location":"server/guides/llms/","title":"LLMs","text":"<p>This guide walks you through the process of starting a LLM server that you can use to host and run large language models locally on the server, while accessing them from your local machine.</p>"},{"location":"server/guides/llms/#ollama","title":"ollama","text":""},{"location":"server/guides/llms/#installation","title":"Installation","text":"<p>Ollama is already installed in the shared directory <code>/projects/main_compute-AUDIT/apps/</code> on the server.</p> <p>Should you for some reason need to install it yourself, follow the manual installation guide on their github page.</p>"},{"location":"server/guides/llms/#inference-server","title":"Inference server","text":"<p>To use it simple load the module file with <code>module load /projects/main_compute-AUDIT/apps/modules/ollama</code>, and then run <code>ollama serve</code> through slurms interactive session.</p> <p>This will start a server on <code>10.84.10.216:8899</code> (which is accessible on any machine connected to the KU-VPN) and store models in a shared cache at <code>/projects/main_compute-AUDIT/data/.ollama/models</code></p>"},{"location":"server/guides/llms/#call-the-api","title":"Call the API","text":"<p>See api documentation, use the ollama-sdk, or the openai client.</p> <p>List local models</p> <pre><code>curl http://10.84.10.216:8899/api/tags\n</code></pre> <p>Pull a models</p> <pre><code>curl http://10.84.10.216:8899/api/pull -d '{\n  \"model\": \"gemma3:27b\"\n}'\n</code></pre> <p>Generate a chat completion</p> <pre><code>curl http://10.84.10.216:8899/api/chat -d '{\n  \"model\": \"gemma3:27b\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"why is the sky blue?\"\n    }\n  ]\n}'\n</code></pre> <pre><code>from openai import OpenAI\n\nclient = OpenAI(\n    base_url = 'http://10.84.10.216:8899/v1',\n    api_key='ollama', # required, but unused\n)\n\nresponse = client.chat.completions.create(\n  model=\"gemma3:27b\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n    {\"role\": \"assistant\", \"content\": \"The LA Dodgers won in 2020.\"},\n    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n  ]\n)\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"server/guides/llms/#vllm","title":"vLLM","text":""},{"location":"server/guides/llms/#installation_1","title":"Installation","text":"<p>Install vllm:</p> <pre><code>uv tool install --with setuptools vllm\n</code></pre>"},{"location":"server/guides/llms/#inference-server_1","title":"Inference server","text":"<p>On the server, in an active Slurm session, run the following command to start the inference server with the specified model from huggingface:</p> <pre><code>vllm serve \"allenai/OLMo-7B-0724-Instruct-hf\" \\ #(1)!\n  --host=10.84.10.216 \\ #(2)!\n  --port=8899 \\ #(3)!\n  --download-dir=/projects/&lt;project-dir&gt;/data/.cache/huggingface \\ #(4)!\n  --dtype=half #(5)!\n</code></pre> <ol> <li>The model name from huggingface</li> <li>The ip address of the slurm gpu server</li> <li>The port of the slurm gpu server</li> <li>Local cache dir for models, remember to substitute  with a specific project eg. <code>ainterviewer-AUDIT</code> <li>For some models, this is needed since the GPUs on the server are a bit old</li> <p>Tip</p> <p>By default, the server is not protected by any authentication.</p> <p>To add simple authentication to the server, you can generate an api-key and use it when starting the server: <pre><code>uuid=$(uuidgen)\necho $uuid\n</code></pre> then, when starting the server, you can use the <code>--api-key=$uuid</code></p>"},{"location":"server/guides/llms/#call-the-api_1","title":"Call the API","text":"<p>Then, you can consume the api through the following endpoint, from anywhere as long as you are connected to the VPN.</p> <p>From the command line:</p> <pre><code># Call the server using curl:\ncurl -X POST \"http://10.84.10.216:8899/v1/chat/completions\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $uuid\" \\\n  --data '{\n    \"model\": \"allenai/OLMo-7B-0724-Instruct-hf\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"What is the capital of France?\"\n      }\n    ]\n  }'\n</code></pre> <p>Or in python, using the openai client:</p> <pre><code>from openai import OpenAI\nclient = OpenAI(\n    base_url=\"http://10.84.10.216:8899/v1\",\n    api_key=\"token-abc123\", # (1)!\n)\n\ncompletion = client.chat.completions.create(\n  model=\"allenai/OLMo-7B-0724-Instruct-hf\",\n  messages=[\n    {\"role\": \"user\", \"content\": \"Why dont scientists trust atoms?\"}\n  ]\n)\n\nprint(completion.choices[0].message)\n</code></pre> <ol> <li>this value doesn't matter, unless you specified it with --api-key, if so    refer to the value specified when starting the server.</li> </ol>"},{"location":"server/guides/ucloud/","title":"UCloud guide","text":"<p>As recently announced, UCloud is now approved for use with personal data. Below is a guide on how to connect remotely to a UCloud terminal app through ssh.</p>"},{"location":"server/guides/ucloud/#accessing-ucloud-terminal-app-through-ssh","title":"Accessing UCloud terminal app through ssh","text":"<p>See also further ressources for UCloud's general guides.</p>"},{"location":"server/guides/ucloud/#setup-ssh","title":"Setup ssh","text":"<p>See UCloud's guide here. Note that you probably already have a public ssh key on your computer.</p> <p>In my case I already have a public ssh key. Therefore I copy my ssh key using</p> <pre><code>cat ~/.ssh/id_ed25519.pub | wl-copy\n</code></pre> <p>and upload it manually to ssh-keys.</p>"},{"location":"server/guides/ucloud/#submit-job","title":"Submit job","text":"<p>Submit your terminal application job here. You can specify different parameters in the application form e.g. selecting access to a specific folder. I select my home folder; this will be available under <code>/work/Home</code> on the remote machine. Also, I select the <code>Machine Type</code> equal to <code>u1-standard-1</code>.</p>"},{"location":"server/guides/ucloud/#access-the-app","title":"Access the app","text":"<p>After having setup the ssh access correctly, the app screen will provide you with an ssh command to run on your local machine. In my case, it gives me the command:</p> <pre><code>ssh ucloud@ssh.cloud.sdu.dk -p 2417\n</code></pre> <p>Note the <code>-p</code> port flag. This will be important when e.g. copying files to the server using <code>scp</code> from you local machine, see scp.</p> <p>Running the <code>ssh</code> command yields the output:</p> <pre><code>\u276f ssh ucloud@ssh.cloud.sdu.dk -p 2417\nThe authenticity of host '[ssh.cloud.sdu.dk]:2417' can't be established.\n...\nAre you sure you want to continue connecting (yes/no/[fingerprint])? yes\n</code></pre> <p>Type <code>yes</code>. Now you should get a nice welcome message:</p> <pre><code>Welcome to Ubuntu 24.04.1 LTS (GNU/Linux 5.15.175.el8 x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/pro\n\nThis system has been minimized by removing packages and content that are\nnot required on a system that users do not log into.\n\nTo restore this content, you can run the 'unminimize' command.\n\nThe programs included with the Ubuntu system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nUbuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by\napplicable law.\n\nucloud@j-5175036-job-0\n----------------------\nOS: Ubuntu 24.04.1 LTS x86_64\nHost: PowerEdge C6420\nKernel: Linux 5.15.175.el8\nUptime: 27 days, 23 hours, 2 mins\nPackages: 1096 (dpkg)\nShell: bash 5.2.21\nCPU: 2 x Intel(R) Xeon(R) Gold 6130 (64) @ 3.70 GHz\nGPU: Matrox Electronics Systems Ltd. Integrated Matrox G200eW3 Graphics Controller\nMemory: 45.09 GiB / 376.53 GiB (12%)\n\n\nucloud in \ud83c\udf10 j-5175036-job-0 in ~\n[ 09:18:38 ] \u279c \n</code></pre> <p>Note the remote machine's specification in the welcome message:</p> <ul> <li>OS: <code>Ubuntu 24.04.1</code></li> <li>CPU: <code>CPU: 2 x Intel(R) Xeon(R) Gold 6130 (64) @ 3.70 GHz</code></li> <li>Memory: <code>Memory: 45.09 GiB / 376.53 GiB (12%)</code></li> </ul> <p>We now have access to a shell in the UCloud environment.</p>"},{"location":"server/guides/ucloud/#work-folder","title":"Work folder","text":"<p>If you have specified access to a specific holder, e.g. you home folder, when requesting the job, it should be located under <code>/work/Home</code>.</p> <pre><code>ucloud in \ud83c\udf10 j-5175036-job-0 in ~\n[ 09:32:09 ] \u279c  cd /work/Home\n\nucloud in \ud83c\udf10 j-5175036-job-0 in /work/Home\n[ 09:32:18 ] \u279c  ls\nJobs  Syncthing  Trash \n</code></pre>"},{"location":"server/guides/ucloud/#scp","title":"scp","text":""},{"location":"server/guides/ucloud/#local-to-remote","title":"local to remote","text":"<p>I create a file locally on my machine and copy it to the remove server using the following commands:</p> <pre><code>\u276f touch msg-to-ucloud.txt\n\u276f echo \"hello ucloud\" &gt;&gt; msg-to-ucloud.txt\n\u276f scp -P 2417 msg-to-ucloud.txt ucloud@ssh.cloud.sdu.dk:/work/Home\nmsg-to-ucloud.txt                                    100%   13     0.6KB/s   00:00\n</code></pre> <p>As it was succesful, we expect the file to be under <code>/work/Home</code> on the remote machine. As shown below, this is the case:</p> <pre><code>ucloud in \ud83c\udf10 j-5175036-job-0 in /work/Home\n[ 09:43:18 ] \u279c  ls\nJobs  Syncthing  Trash  msg-to-ucloud.txt\n\nucloud in \ud83c\udf10 j-5175036-job-0 in /work/Home\n[ 09:43:19 ] \u279c  cat msg-to-ucloud.txt\nhello ucloud\n</code></pre> <p>If you inspect you home folder under drives you should also be able to see and access the file.</p>"},{"location":"server/guides/ucloud/#remote-to-local","title":"remote to local","text":"<p>Create a file on the remote machine:</p> <pre><code>ucloud in \ud83c\udf10 j-5175067-job-0 in ~\n[ 10:02:52 ] \u279c  echo \"hello world\" &gt;&gt; msg-to-local.txt\n</code></pre> <p>Then on your local machine, run the following command (specify the port that you have gotten allocated):</p> <pre><code>\u276f scp -P 2483 ucloud@ssh.cloud.sdu.dk:msg-to-local.txt .\nmsg-to-local.txt                                    100%   12     0.3KB/s   00:00\n\u276f cat msg-to-local.txt\nhello world\n</code></pre> <p>Thus, the remote file has been succesfully copied to the local machine.</p> <p>Note that the port has changed in the command above from <code>2417</code> to <code>2483</code>. This is because, while writing this guide, my requested 1-hour session from UCloud ran out, and therefore I requested another machine and got a new port \ud83d\ude00</p>"},{"location":"server/guides/ucloud/#connecting-from-sodas-server-to-ucloud-server","title":"Connecting from SODAS server to UCloud server","text":"<ul> <li><code>ssh</code> into the SODAS server</li> <li> <p>Copy your <code>id_rsa.pub</code> file into your clipboard or another location; inspect   it by running</p> <pre><code>cat ~/.ssh/id_rsa.pub\n</code></pre> </li> </ul> <ul> <li>If you don't have a ssh key on the server, follow the guide   here   or any other on how to create a ssh key pair</li> <li>Go to the SSH keys page on UCloud and   paste your public key with a suitable title</li> <li>You should now be able to <code>ssh</code> from the SODAS server to UCloud directly<ul> <li>This allows you to use scp to copy files from the server to UCloud   directly (while respecting all data rules)</li> </ul> </li> </ul>"},{"location":"server/guides/ucloud/#notice","title":"Notice","text":"<ul> <li>The port range that UCloud assigns has been opened from the SODAS server</li> <li>This port range is subject to change in the future</li> <li>If the guide above does not work, the port range may have changed; if so,   contact the server administrators</li> </ul>"},{"location":"server/guides/ucloud/#further-ressources","title":"Further ressources","text":"<p>See the excellent guides at UCloud:</p> <ul> <li>https://docs.cloud.sdu.dk/guide/login.html</li> <li>https://docs.cloud.sdu.dk/guide/submitting.html<ul> <li>https://docs.cloud.sdu.dk/guide/submitting.html#configure-ssh-access</li> </ul> </li> <li>https://docs.cloud.sdu.dk/hands-on/use-cases.html</li> </ul>"}]}